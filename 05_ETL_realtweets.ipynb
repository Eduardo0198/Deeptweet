{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e40bf2",
   "metadata": {},
   "source": [
    "## **05 ETL - TWEETS REALES**\n",
    "## José Eduardo Viveros Escamilla | A01710605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b49f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4709145a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-01T18:28:41</td>\n",
       "      <td>user_1293</td>\n",
       "      <td>Deep Learning makes my workflow so much easier!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-16T00:56:18</td>\n",
       "      <td>user_3162</td>\n",
       "      <td>OpenAI is trending again.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-09T17:55:06</td>\n",
       "      <td>user_833</td>\n",
       "      <td>Hot take: OpenAI is overrated.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-11T12:43:01</td>\n",
       "      <td>user_1163</td>\n",
       "      <td>Wow, Deep Learning just blew my mind!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-03T06:04:02</td>\n",
       "      <td>user_485</td>\n",
       "      <td>People keep talking about Deep Learning today.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date       user  \\\n",
       "0  2024-04-01T18:28:41  user_1293   \n",
       "1  2024-05-16T00:56:18  user_3162   \n",
       "2  2025-01-09T17:55:06   user_833   \n",
       "3  2024-07-11T12:43:01  user_1163   \n",
       "4  2024-12-03T06:04:02   user_485   \n",
       "\n",
       "                                              text  label  \n",
       "0  Deep Learning makes my workflow so much easier!      1  \n",
       "1                        OpenAI is trending again.      0  \n",
       "2                   Hot take: OpenAI is overrated.      0  \n",
       "3            Wow, Deep Learning just blew my mind!      1  \n",
       "4   People keep talking about Deep Learning today.      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_live = pd.read_csv(r\"C:\\Users\\josed\\Documents\\IA\\BENJI\\data\\raw_data\\real_tweets_tech_10000.csv\")\n",
    "df_live.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7886018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Learning makes my workflow so much easier!</td>\n",
       "      <td>deep learning makes my workflow so much easier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenAI is trending again.</td>\n",
       "      <td>openai is trending again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hot take: OpenAI is overrated.</td>\n",
       "      <td>hot take openai is overrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow, Deep Learning just blew my mind!</td>\n",
       "      <td>wow deep learning just blew my mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People keep talking about Deep Learning today.</td>\n",
       "      <td>people keep talking about deep learning today</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text  \\\n",
       "0  Deep Learning makes my workflow so much easier!   \n",
       "1                        OpenAI is trending again.   \n",
       "2                   Hot take: OpenAI is overrated.   \n",
       "3            Wow, Deep Learning just blew my mind!   \n",
       "4   People keep talking about Deep Learning today.   \n",
       "\n",
       "                                       text_clean  \n",
       "0  deep learning makes my workflow so much easier  \n",
       "1                        openai is trending again  \n",
       "2                    hot take openai is overrated  \n",
       "3             wow deep learning just blew my mind  \n",
       "4   people keep talking about deep learning today  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# BLOQUE 3 — Función de limpieza (idéntica a v1 y v2)\n",
    "# ================================================================\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # Quitar URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "\n",
    "    # Quitar menciones\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "    # Quitar hashtags (solo el #)\n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "\n",
    "    # Quitar emojis básicos\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "\n",
    "    # Quitar puntuación\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # Quitar múltiples espacios\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Aplicar limpieza\n",
    "df_live[\"text_clean\"] = df_live[\"text\"].apply(clean_text)\n",
    "df_live[[\"text\", \"text_clean\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9ecbbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total muestras: 10000\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# BLOQUE 4 — Seleccionar X (texto) y y (labels)\n",
    "# ================================================================\n",
    "\n",
    "X = df_live[\"text_clean\"]\n",
    "y = df_live[\"label\"].astype(int)\n",
    "\n",
    "print(\"Total muestras:\", len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3b3df56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaños:\n",
      "Train: 6000\n",
      "Val: 2000\n",
      "Test: 2000\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# BLOQUE 5 — Dividir Train / Val / Test\n",
    "# ================================================================\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.40, random_state=42, stratify=y)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"Tamaños:\")\n",
    "print(\"Train:\", len(X_train))\n",
    "print(\"Val:\", len(X_val))\n",
    "print(\"Test:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "019db126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# BLOQUE 6 — Cargar tokenizer original del v1_base\n",
    "# ================================================================\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "tokenizer.num_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c550d6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 50), (2000, 50), (2000, 50))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# BLOQUE 7 — Tokenizar todo el texto\n",
    "# ================================================================\n",
    "# Se usa tokenización con EXACTA configuración del v1_base:\n",
    "#   - mismo vocabulario\n",
    "#   - misma longitud máxima (MAX_LEN = 50)\n",
    "# ================================================================\n",
    "\n",
    "MAX_LEN = 50\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq   = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq  = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\")\n",
    "X_val_pad   = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding=\"post\")\n",
    "X_test_pad  = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding=\"post\")\n",
    "\n",
    "X_train_pad.shape, X_val_pad.shape, X_test_pad.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "956099cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta creada: data/processed_data/v3_realtweets/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = \"data/processed_data/v3_realtweets/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Carpeta creada:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26e15ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos guardados.\n"
     ]
    }
   ],
   "source": [
    "np.save(OUTPUT_DIR +\"X_train_live.npy\", X_train_pad)\n",
    "np.save(OUTPUT_DIR +\"X_val_live.npy\",   X_val_pad)\n",
    "np.save(OUTPUT_DIR +\"X_test_live.npy\",  X_test_pad)\n",
    "\n",
    "np.save(OUTPUT_DIR +\"y_train_live.npy\", y_train)\n",
    "np.save(OUTPUT_DIR +\"y_val_live.npy\",   y_val)\n",
    "np.save(OUTPUT_DIR +\"y_test_live.npy\",  y_test)\n",
    "\n",
    "print(\"Archivos guardados.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BENJI)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
